<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Wells Fargo Analytics Competition by emilyberich</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Wells Fargo Analytics Competition</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/emilyberich/Wells-Fargo-Analytics-Competition" class="btn">View on GitHub</a>
      <a href="https://github.com/emilyberich/Wells-Fargo-Analytics-Competition/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/emilyberich/Wells-Fargo-Analytics-Competition/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="other-contributors" class="anchor" href="#other-contributors" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Other Contributors</em>
</h2>

<p>Katie Duchinski (<a href="https://github.com/kduchinski" class="user-mention">@kduchinski</a>) and Kenzie Nash (<a href="https://github.com/nashkenziem" class="user-mention">@nashkenziem</a>)</p>

<h3>
<a id="social-media-sites-are-a-font-of-knowledge-for-businesses-as-they-act-as-a-platform-where-real-world-consumers-can-instantly-provide-the-company-with-feedback-and-input-on-their-experiences-the-overall-attitude-the-public-takes-to-a-business-on-social-media--one-of-praise-or-one-of-complaint--is-quantifiable-and-analyzable-feedback-of-the-companies-performance-it-is-a-measurable-indicator-of-the-functionality-of-the-business-revealing-whether-the-majority-of-its-client-base-is-satisfied-or-discontented-with-their-services" class="anchor" href="#social-media-sites-are-a-font-of-knowledge-for-businesses-as-they-act-as-a-platform-where-real-world-consumers-can-instantly-provide-the-company-with-feedback-and-input-on-their-experiences-the-overall-attitude-the-public-takes-to-a-business-on-social-media--one-of-praise-or-one-of-complaint--is-quantifiable-and-analyzable-feedback-of-the-companies-performance-it-is-a-measurable-indicator-of-the-functionality-of-the-business-revealing-whether-the-majority-of-its-client-base-is-satisfied-or-discontented-with-their-services" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Social media sites are a font of knowledge for businesses, as they act as a platform where real-world consumers can instantly provide the company with feedback and input on their experiences. The overall attitude the public takes to a business on social media- one of praise or one of complaint- is quantifiable and analyzable feedback of the companies’ performance. It is a measurable indicator of the functionality of the business, revealing whether the majority of its client base is satisfied or discontented with their services.</em>
</h3>

<h1>
<a id="our-task" class="anchor" href="#our-task" aria-hidden="true"><span class="octicon octicon-link"></span></a>Our Task</h1>

<p><strong>Analyze text from posts on the social media sites Twitter and Facebook regarding Banks A-D.</strong> </p>

<p><em>We believe analyzing the frequent topics and sentiment of within these social media posts would provide the banks with useful consumer feedback. Additionally, we believe that examining words commonly used together within a social media post through term adjacency would provide insight into the social media posts regarding Banks A-D.</em></p>

<h2>
<a id="word-frequency" class="anchor" href="#word-frequency" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Word Frequency</em>
</h2>

<p>First, we determined the identities of the most frequently used words, and graphically represented these frequent words in word clouds and frequency plots. </p>

<ul>
<li>
<p>Word clouds allowed for a clear and easily comprehensible visual representation of the topics addressed in social media posts. </p>

<h4>
<a id="word-cloud-for-entire-dataset" class="anchor" href="#word-cloud-for-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word Cloud for Entire Dataset</h4>

<p><a href="http://imgur.com/i0t63I7"><img src="http://i.imgur.com/i0t63I7.png" title="source: imgur.com"></a></p>
</li>
<li>
<p>Frequency plots were also included so that a numeric representation of term frequency was available, in addition to the more subjective representation of frequency seen in the word clouds. </p>

<h4>
<a id="frequency-plot-for-entire-dataset" class="anchor" href="#frequency-plot-for-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency Plot for Entire Dataset</h4>

<p><a href="http://imgur.com/L6t1Xlb"><img src="http://i.imgur.com/L6t1Xlb.png" title="source: imgur.com"></a></p>
</li>
</ul>

<p><em>In each of these graphic representations, the most common topics throughout the social media text are clearly presented. Visual representations were created for the entirety of the social media text, and were then created for each of the individual banks (i.e., Banks A, B, C, and D).</em></p>

<h2>
<a id="sentiment-analysis" class="anchor" href="#sentiment-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Sentiment Analysis</em>
</h2>

<p>To further analyze the attitude of the consumers regarding these topics, we determined the sentiment, <em>i.e</em>. the positive, negative, or neutral connotation, within the social media posts. </p>

<ul>
<li><p>The neutral terms commonly included words regarding banking and financing, such as “checking” and “online.” Regarding these frequent neutral words further indicated the topics that consumers were posting about. </p></li>
<li><p>Meanwhile, the positive or negative frequently used terms provided feedback as to the attitudes consumers had towards the company. The sentiment scores were then plotted and graphically represented with a box chart. </p></li>
</ul>

<p><em>Sentiment was scored on a scale of 0-100, with 0 being associated with negative sentiment and 100 being associated with positive sentiment. Neutral words did not receive a sentiment score. The sentiment scores were averaged, and these averages were represented through a bar graph. Sentiment analysis and graphical representations of same were generated for the entire dataset, as well as for each individual bank. Further, each graph compared the sentiment of frequent terms seen between two different social media sites, Twitter and Facebook</em></p>

<h4>
<a id="average-sentiment-scores-for-entire-dataset" class="anchor" href="#average-sentiment-scores-for-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Average Sentiment Scores for Entire Dataset</h4>

<p><a href="http://imgur.com/d8mkFuh"><img src="http://i.imgur.com/d8mkFuh.png?1" title="source: imgur.com"></a></p>

<h4>
<a id="boxplot-illustrating-sentiment-scores-for-entire-dataset" class="anchor" href="#boxplot-illustrating-sentiment-scores-for-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boxplot Illustrating Sentiment Scores for Entire Dataset</h4>

<p><a href="http://imgur.com/X3n79rf"><img src="http://i.imgur.com/X3n79rf.png?1" title="source: imgur.com"></a></p>

<h1>
<a id="how-did-we-execute-these-goals" class="anchor" href="#how-did-we-execute-these-goals" aria-hidden="true"><span class="octicon octicon-link"></span></a>How did we execute these goals?</h1>

<p>By using RStudio, we were able to write code allowing for the aforementioned analysis of the social media posts.</p>

<p><a href="http://imgur.com/6fCtXfZ"><img src="http://i.imgur.com/6fCtXfZ.png" title="source: imgur.com"></a></p>

<h2>
<a id="term-adjacency-matrices" class="anchor" href="#term-adjacency-matrices" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Term Adjacency Matrices</em>
</h2>

<p>Term adjacency matrices provide a visual representation of words that were used together within social media posts. </p>

<ul>
<li><p>The terms shown in the term adjacency matrices are the words with the most connections from each of Bank A-D's term document matrices.</p></li>
<li><p>Additionally, the strength of the connection (<em>i.e.</em>, the number of times the two words were jointly used in the social media posts) is indicated by text size- the larger the text, the stronger the connection. Furthermore, the transparency and weight of the lines, or edges, are indicative of the weight of the connection.</p></li>
</ul>

<p><em>In future projects, we would like to refine the presentation of the term adjacency matrices through finding the best scale to visually represent the strengths and weights of the connections within these large data sets.</em></p>

<h3>
<a id="an-example-of-the-term-adjacency-matrix-for-bank-c" class="anchor" href="#an-example-of-the-term-adjacency-matrix-for-bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a>An example of the term adjacency matrix, for Bank C</h3>

<p><a href="http://imgur.com/Dk9I0M8"><img src="http://i.imgur.com/Dk9I0M8.png" title="source: imgur.com"></a></p>

<h1>
<a id="our-code" class="anchor" href="#our-code" aria-hidden="true"><span class="octicon octicon-link"></span></a>Our Code</h1>

<h2>
<a id="creation-of-data-frame-and-corpus" class="anchor" href="#creation-of-data-frame-and-corpus" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Creation of Data Frame and Corpus</em>
</h2>

<p>Dataframe Creation</p>

<pre><code>df = read.table('dataset.txt',sep="|",header=T)
spellDoc(doc, wordHandler = DocSpeller(), checker = docChecker(speller), speller = getSpeller(conf), 
conf = createSpellConfig())
</code></pre>

<p>Corpus Creation</p>

<pre><code>df.texts = as.data.frame(df[,ncol(df)])

colnames(df.texts) = 'FullText' 
</code></pre>

<p>Remove non-ascii characters</p>

<pre><code>df.texts.clean = as.data.frame(iconv(df.texts$FullText, "latin1", "ASCII", sub=""))

for(i in 1:nrow(df))

{

df.texts.clean[i,] = check_spelling(df.texts.clean[i,], range = 2, assume.first.correct=TRUE,
dictionary=qdapDictionaries::GradyAugmented,parallel=TRUE,cores=parallel::detectCores()/2,n.suggests=8)

}

colnames(df.texts.clean) = 'FullText'
</code></pre>

<h2>
<a id="apply-tm-library" class="anchor" href="#apply-tm-library" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Apply TM Library</em>
</h2>

<pre><code>library(tm) 

docs &lt;- Corpus(DataframeSource(df.texts.clean))
</code></pre>

<h2>
<a id="cleaning-the-text" class="anchor" href="#cleaning-the-text" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Cleaning the text</em>
</h2>

<p>Remove numbers and punctuation </p>

<pre><code>removeNumPunct &lt;- function(x) gsub("[^[:alpha:][:space:]]*", "", x)

docs &lt;- tm_map(docs, content_transformer(removeNumPunct))
</code></pre>

<p>Remove stopwords, from Smart English List found on CRAN, as well as hard-coding out several words </p>

<pre><code>myStopwords &lt;- c(stopwords(kind='SMART'), "available", "via",  "twithndl","twithndlBankA",
"twithndlBankB","twithndlBankC","twithndlBankD","twithndlBankE","INTERNET",
"Name","PHONE","ADDRESS","rettwi     t","Nameresp","ly", "https", "bit","dlvr")

docs &lt;- tm_map(docs, removeWords, myStopwords, lazy = T)
</code></pre>

<p>Remove white space </p>

<pre><code>docs &lt;- tm_map(docs, stripWhitespace)

docsCopy &lt;- docs
docs &lt;- tm_map(docs, stemDocument)
docs &lt;- Corpus(VectorSource(docs))
</code></pre>

<h2>
<a id="creation-of-smaller-corpora-for-each-bank-a-d" class="anchor" href="#creation-of-smaller-corpora-for-each-bank-a-d" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Creation of smaller corpora for each Bank A-D</em>
</h2>

<p>Corpora Creation </p>

<pre><code>bankA.idx = which(sapply(df$FullText,function(x) grepl("BankA",x)))

bankB.idx = which(sapply(df$FullText,function(x) grepl("BankB",x)))

bankC.idx = which(sapply(df$FullText,function(x) grepl("BankC",x)))

bankD.idx = which(sapply(df$FullText,function(x) grepl("BankD",x)))
</code></pre>

<p>Additional cleaning within the corpora </p>

<pre><code>bankA.docs = docs[bankA.idx]

bankA.docs &lt;- tm_map(bankA.docs, removeWords, c("BankA"), lazy = T)

bankB.docs = docs[bankB.idx]

bankB.docs &lt;- tm_map(bankB.docs, removeWords, c("BankB", "twithndlBankBhelp"), lazy = T)

bankC.docs = docs[bankC.idx]

bankC.docs &lt;- tm_map(bankC.docs, removeWords, c("BankC"), lazy = T)

bankD.docs = docs[bankD.idx]

bankD.docs &lt;- tm_map(bankD.docs, removeWords, c("BankD"), lazy = T)
</code></pre>

<p>Create term document matrices for each bank</p>

<pre><code> tdm &lt;- TermDocumentMatrix(docs, control = list(wordLengths = c(1, Inf)))

(freq.terms &lt;- findFreqTerms(tdm, lowfreq = 5000))

tdmA &lt;- TermDocumentMatrix(bankA.docs, control = list(wordLengths = c(1, Inf)))

(freq.terms &lt;- findFreqTerms(tdmA, lowfreq = 1000))

tdmB &lt;- TermDocumentMatrix(bankB.docs, control = list(wordLengths = c(1, Inf)))

(freq.terms &lt;- findFreqTerms(tdmB, lowfreq = 1000))

tdmC &lt;- TermDocumentMatrix(bankC.docs, control = list(wordLengths = c(1, Inf)))

(freq.terms &lt;- findFreqTerms(tdmC, lowfreq = 1000))

tdmD &lt;- TermDocumentMatrix(bankD.docs, control = list(wordLengths = c(1, Inf)))

(freq.terms &lt;- findFreqTerms(tdmD, lowfreq = 1000))
</code></pre>

<h2>
<a id="sentiment-analysis-1" class="anchor" href="#sentiment-analysis-1" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Sentiment Analysis</em>
</h2>

<p>Apply dictionaries of positive and negative words</p>

<pre><code>pos &lt;- scan('positive-words.txt',what='character',comment.char=';')

neg &lt;- scan('negative-words.txt',what='character',comment.char=';')
</code></pre>

<p>Creation of the custom function score.sentiment </p>

<pre><code>score.sentiment = function(sentences, pos.words, neg.words, .progress='none')

{

require(plyr)

require(stringr)

scores = laply(sentences, function(sentence, pos.words, neg.words) {

word.list = str_split(sentence, '\\s+')

words = unlist(word.list)  

# compare our words to the dictionaries of positive &amp; negative terms

pos.matches = match(words, pos.words)

neg.matches = match(words, neg.words)  

# match() returns the position of the matched term or NA

# we just want a TRUE/FALSE:

pos.matches = !is.na(pos.matches)

neg.matches = !is.na(neg.matches)

# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():

score = sum(pos.matches) - sum(neg.matches)

return(score)

}, pos.words, neg.words, .progress=.progress )

scores.df = data.frame(score=scores, text=sentences)

return(scores.df)

}
</code></pre>

<p>Sentiment scoring for Bank A; repeat this for each bank </p>

<pre><code>df.sentiment = df[bankA.idx,]

scores = score.sentiment(df.sentiment$FullText, pos, neg, .progress='text')

scores$very.pos = as.numeric(scores$score &gt;= 2)

scores$very.neg = as.numeric(scores$score &lt;= -2)

numpos = sum(scores$very.pos)

numneg = sum(scores$very.neg)

global_score = round( 100 * numpos / (numpos + numneg) )

scores$mediatype = df.sentiment$MediaType

cols = c("#7CAE00", "#00BFC4")

names(cols) = c("twitter", "facebook")
</code></pre>

<p>Create boxplot for Bank A; repeat for each Bank </p>

<pre><code>library(ggplot2)

ggplot(scores, aes(x=mediatype, y=score, group=mediatype)) +

geom_boxplot(aes(fill=mediatype)) +

scale_fill_manual(values=cols) +

geom_jitter(colour="gray40",position=position_jitter(width=0.2), alpha=0.3) +

labs(title = "Media Type's Sentiment Scores") + 

xlab('Media Type') + ylab('Sentiment Score')
</code></pre>

<p>Create bar graph of average sentiment scores for Bank A; repeat for each bank </p>

<pre><code>meanscore = tapply(scores$score, scores$mediatype, mean)

df.plot = data.frame(mediatype=names(meanscore), meanscore=meanscore)

df.plot$mediatypes &lt;- reorder(df.plot$mediatype, df.plot$meanscore)

ggplot(df.plot, aes(x = factor(mediatypes), y = meanscore, fill=mediatypes)) +

geom_bar(stat="identity") +

scale_fill_manual(values=cols[order(df.plot$meanscore)]) +

labs(title = "Average Sentiment Score") + 

xlab('Media Type') + ylab('Average Score')

# barplot of average very positive

mediatype_pos = ddply(scores, .(mediatype), summarise, mean_pos=mean(very.pos))

mediatype_pos$mediatypes &lt;- reorder(mediatype_pos$mediatype, mediatype_pos$mean_pos)

ggplot(mediatype_pos, aes(x = factor(mediatype), y = mean_pos, fill=mediatype)) +

geom_bar(stat="identity") +

scale_fill_manual(values=cols[order(df.plot$meanscore)]) +

labs(title = "Average Very Negative Sentiment Score") + 

xlab('Media Type') + ylab('Average Score')

mediatype_neg = ddply(scores, .(mediatype), summarise, mean_neg=mean(very.neg))

mediatype_neg$mediatypes &lt;- reorder(mediatype_neg$mediatype, mediatype_neg$mean_neg)

ggplot(mediatype_neg, aes(x = factor(mediatype), y = mean_neg, fill=mediatype)) +

geom_bar(stat="identity") +

scale_fill_manual(values=cols[order(df.plot$meanscore)]) +

labs(title = "Average Very Negative Sentiment Score") + 

xlab('Media Type') + ylab('Average Score')
</code></pre>

<h2>
<a id="spell-check-through-manual-replacement-of-misspelled-frequently-used-words" class="anchor" href="#spell-check-through-manual-replacement-of-misspelled-frequently-used-words" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>"Spell Check" through manual replacement of misspelled, frequently used words</em>
</h2>

<p>Define, once only </p>

<pre><code>dictCorpusA = VCorpus(VectorSource(dimnames(tdmA)$Terms))

dictCorpusB = VCorpus(VectorSource(dimnames(tdmB)$Terms))

dictCorpusC = VCorpus(VectorSource(dimnames(tdmC)$Terms))

dictCorpusD = VCorpus(VectorSource(dimnames(tdmD)$Terms))

dictCorpus = VCorpus(VectorSource(dimnames(tdm)$Terms))

stemCompletion_mod &lt;- function(x,dict=dictCorpus) {

paste(stemCompletion(unlist(strsplit(as.character(x)," ")),dict, type="longest"),sep=" ",collapse=" ")

}
</code></pre>

<p>Manually replace incorrect terms; here, term replacement for Bank A is shown. </p>

<pre><code>terms = dimnames(tdmA)$Terms

for (i in 1:length(terms)) {

if (terms[i] == 'appli') {

    terms[i] = 'application'

} else if (terms[i] == 'busi') {

    terms[i] = 'business'

}else if (terms[i] == 'financi') {

    terms[i] = 'financial'

}else if (terms[i] == 'manag') {

    terms[i] = 'manage'

}else if (terms[i] == 'bankac') {

    terms[i] = 'banka'

}else if (terms[i] == 'charg') {

    terms[i] = 'charge'

}else if (terms[i] == 'famili') {

    terms[i] = 'families'

}else if (terms[i] == 'compani') {

    terms[i] = 'companies'

}else if (terms[i] == 'fuck') {

    terms[i] = 'f***'

}else if (terms[i] == 'donat') {

    terms[i] = 'donation'

}else if (terms[i] == 'mortgag') {

    terms[i] = 'mortgage'

}else if (terms[i] == 'peopl') {

    terms[i] = 'people'

}else if (terms[i] == 'servic') {

    terms[i] = 'service'

}else if (terms[i] == 'dlvr') {

    terms[i] = ''

}else if (terms[i] == 'nameresp') {

    terms[i] = ''

}else if (terms[i] == 'bit') {

    terms[i] = ''

}else if (terms[i] == 'bank') {

    terms[i] = ''

}


 }
</code></pre>

<p>Term replacement for Bank B.</p>

<pre><code>terms = dimnames(tdmB)$Terms

for (i in 1:length(terms)) {

if (terms[i] == 'bank'){

    terms[i] = ''

} else if (terms[i] == 'busi') {

    terms[i] = 'business'

}else if (terms[i] == 'financi') {

    terms[i] = 'financial'

}else if (terms[i] == 'manag') {

    terms[i] = 'manage'

}else if (terms[i] == 'charg') {

    terms[i] = 'charge'

}else if (terms[i] == 'corpor') {

    terms[i] = 'corporate'

}else if (terms[i] == 'feedbankb') {

    terms[i] = ''

}else if (terms[i] == 'fuck') {

    terms[i] = 'f***'

}else if (terms[i] == 'mortgag') {

    terms[i] = 'mortgage'

}else if (terms[i] == 'peopl') {

    terms[i] = 'people'

}else if (terms[i] == 'servic') {

    terms[i] = 'service'

}else if (terms[i] == 'dlvr') {

    terms[i] = ''

}else if (terms[i] == 'nameresp') {

    terms[i] = ''

}else if (terms[i] == 'bit') {

    terms[i] = ''

}else if (terms[i] == 'tt') {

    terms[i] = ''

}else if (terms[i] == 'ift') {

    terms[i] = ''

}else if (terms[i] == 'compani') {

    terms[i] = 'companies'

}else if (terms[i] == 'locat') {

    terms[i] = 'location'

}

}

dimnames(tdmB)$Terms = terms
</code></pre>

<p>Term replacement for Bank C.</p>

<pre><code>terms = dimnames(tdmC)$Terms

for (i in 1:length(terms)) {

if (terms[i] == 'busi') {

    terms[i] = 'business'

}else if (terms[i] == 'bit') {

    terms[i] = ''

}else if (terms[i] == 'ift') {

    terms[i] = ''

}else if (terms[i] == 'tt') {

    terms[i] = ''

}else if (terms[i] == 'bank') {

    terms[i] = ''

}else if (terms[i] == 'ank') {

    terms[i] = ''

}else if (terms[i] == 'nameresp') {

    terms[i] = ''

}else if (terms[i] == 'fb') {

    terms[i] = ''

}else if (terms[i] == 'gl') {

    terms[i] = ''

}else if (terms[i] == 'goo') {

    terms[i] = ''

}else if (terms[i] == 'ow') {

    terms[i] = ''

}else if (terms[i] == 'compani') {

    terms[i] = 'companies'

}else if (terms[i] == 'charg') {

    terms[i] = 'charge'

}else if (terms[i] == 'chang') {

    terms[i] = 'change'

}else if (terms[i] == 'financi') {

    terms[i] = 'financial'

}else if (terms[i] == 'reiter') {

    terms[i] = 'reiterate'

}

}

dimnames(tdmC)$Terms = terms
</code></pre>

<p>Term Replacement for Bank D </p>

<pre><code>terms = dimnames(tdmD)$Terms

for (i in 1:length(terms)) {

if (terms[i] == 'appli') {

    terms[i] = 'application'

}else if (terms[i] == 'busi') {

    terms[i] = 'business'

}else if (terms[i] == 'https') {

    terms[i] = ''

}else if (terms[i] == 'manag') {

    terms[i] = 'manage'

}else if (terms[i] == 'servic') {

    terms[i] = 'service'

}else if (terms[i] == 'advis') {

    terms[i] = 'advise'

}else if (terms[i] == 'mortgag') {

    terms[i] = 'mortgage'

}else if (terms[i] == 'reiter') {

    terms[i] = 'reiterate'

}else if (terms[i] == 'ift') {

    terms[i] = ''

}else if (terms[i] == 'tt') {

    terms[i] = ''

}else if (terms[i] == 'financi') {

    terms[i] = 'financial'

}else if (terms[i] == 'fb') {

    terms[i] = ''

}else if (terms[i] == 'compani') {

    terms[i] = 'companies'

}else if (terms[i] == 'bank') {

    terms[i] = ''

}else if (terms[i] == 'charg') {

    terms[i] = 'charge'

}else if (terms[i] == 'peopl') {

    terms[i] = 'people'

}else if (terms[i] == 'rais') {

    terms[i] = 'raise'

}

}
</code></pre>

<h2>
<a id="create-term-frequency-graph" class="anchor" href="#create-term-frequency-graph" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Create Term Frequency Graph</em>
</h2>

<p>Here, creation of graph for Bank A is shown. Repeat for every bank. </p>

<pre><code>library(slam)

bankA.docs &lt;- rollup(bankA.docs, 2, na.rm=TRUE, FUN = sum)

liblibterm.freqA &lt;- rowSums(as.matrix(tdmA))

term.freqA &lt;- subset(term.freqA, term.freqA &gt;= 1000)

df.A &lt;- data.frame(term = names(term.freqA), freq = term.freqA)

library(slam)

(freq.terms &lt;- findFreqTerms(tdmA, lowfreq = 1000))      

bankA.docs &lt;- rollup(bankA.docs, 2, na.rm=TRUE, FUN = sum)

term.freqA &lt;- rowSums(as.matrix(tdmA))

term.freqA &lt;- subset(term.freqA, term.freqA &gt;= 1000)

df.A &lt;- data.frame(term = names(term.freqA), freq = term.freqA)

tdmA &lt;- rollup(tdmA, 2, na.rm=TRUE, FUN = sum)

term.freqA &lt;- rowSums(as.matrix(tdmA))

term.freqA &lt;- subset(term.freqA, term.freqA &gt;= 1000)

df.A &lt;- data.frame(term = names(term.freqA), freq = term.freqA)
</code></pre>

<h2>
<a id="creation-of-word-cloud" class="anchor" href="#creation-of-word-cloud" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Creation of Word Cloud</em>
</h2>

<p>Here, creation of word cloud for Bank A is shown. Repeat for each bank. </p>

<pre><code>mA &lt;- as.matrix(tdmA)

word.freq &lt;- sort(rowSums(mA), decreasing = T)

pal &lt;- brewer.pal(9, "BuGn")

pal &lt;- pal[-(1:4)]

library(wordcloud)

wordcloud(words = names(word.freq), freq = word.freq, min.freq=700, random.order=F, random.color=F, colors = pal)
</code></pre>

<h2>
<a id="creation-of-term-adjacency-matrices" class="anchor" href="#creation-of-term-adjacency-matrices" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Creation of Term Adjacency Matrices</em>
</h2>

<p>Apply sparse function to term document matrix; here, the term document matrix of Bank D is used </p>

<pre><code>tdmD.sparse &lt;- removeSparseTerms(tdmD, 0.98)
termDocMatrix &lt;- as.matrix(tdmD.sparse)
</code></pre>

<p>Transform "sparse" term document matrix into a Boolean matrix </p>

<pre><code>termDocMatrix[termDocMatrix&gt;=1] &lt;- 1
</code></pre>

<p>Transform Boolean matrix into term adjacency matrix </p>

<pre><code>termMatrix &lt;- termDocMatrix %*% t(termDocMatrix)
termMatrix[5:10,5:10]
</code></pre>

<p>Create visual of term adjacency matrix, using the CRAN package igraph </p>

<pre><code>library(igraph)
g &lt;- graph.adjacency(termMatrix, weighted=T, mode = "undirected")
g &lt;- simplify(g)
#v=verticles 
V(g)$label &lt;- V(g)$name
V(g)$degree &lt;- degree(g)
set.seed(3952)
layout1 &lt;- layout.fruchterman.reingold(g)
plot(g, layout=layout1)
</code></pre>

<p>Improve visual's layout and clarity </p>

<pre><code>V(g)$label.cex &lt;- 2.2*colSums(termMatrix)/max(colSums(termMatrix))+.2
V(g)$label.color &lt;- rgb(0, 0, .2, .8)
V(g)$frame.color &lt;- NA
egam &lt;- (log(E(g)$weight)+2) / max(log(E(g)$weight)+2)
E(g)$color &lt;- rgb(.5, .5, 0, egam)
E(g)$width &lt;- egam
#plot the graph in layout1
plot(g, layout=layout1)
</code></pre>

<h5>
<a id="in-future-work-on-this-project-we-would-like-to-create-a-term-adjacency-matrix-for-bank-a---currently-however-technical-and-temporal-constraints-prevent-us-from-providing-same" class="anchor" href="#in-future-work-on-this-project-we-would-like-to-create-a-term-adjacency-matrix-for-bank-a---currently-however-technical-and-temporal-constraints-prevent-us-from-providing-same" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>In future work on this project, we would like to create a term adjacency matrix for Bank A-- currently, however, technical and temporal constraints prevent us from providing same.</em>
</h5>

<h1>
<a id="results" class="anchor" href="#results" aria-hidden="true"><span class="octicon octicon-link"></span></a>Results</h1>

<h2>
<a id="entire-dataset" class="anchor" href="#entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Entire Dataset</em>
</h2>

<h3>
<a id="word-frequency-1" class="anchor" href="#word-frequency-1" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Word Frequency</strong>
</h3>

<p>Most frequently discussed words, related to banking, from the entire dataset:</p>

<ol>
<li>Credit </li>
<li>Check </li>
<li>Card</li>
<li>Money </li>
<li>Finance</li>
<li>Custom </li>
<li>Call </li>
<li>Share </li>
</ol>

<h4>
<a id="frequency-plot-entire-dataset" class="anchor" href="#frequency-plot-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency Plot, Entire Dataset</h4>

<p><a href="http://imgur.com/L6t1Xlb"><img src="http://i.imgur.com/L6t1Xlb.png" title="source: imgur.com"></a></p>

<h5>
<a id="word-cloud-entire-dataset" class="anchor" href="#word-cloud-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word Cloud, Entire Dataset</h5>

<p><a href="http://imgur.com/i0t63I7"><img src="http://i.imgur.com/i0t63I7.png" title="source: imgur.com"></a></p>

<h3>
<a id="sentiment-analysis-2" class="anchor" href="#sentiment-analysis-2" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Sentiment Analysis</strong>
</h3>

<p>Average Sentiment Score of Entire Dataset: 62</p>

<p><em>Facebook was slightly more positive as Twitter, and Facebook had notably more variability and more instances of strong sentiment.</em></p>

<h4>
<a id="average-sentiment-scores-entire-dataset" class="anchor" href="#average-sentiment-scores-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Average Sentiment Scores, Entire Dataset</h4>

<p><a href="http://imgur.com/d8mkFuh"><img src="http://i.imgur.com/d8mkFuh.png?1" title="source: imgur.com"></a></p>

<h4>
<a id="boxplot-illustrating-sentiment-scores-entire-dataset" class="anchor" href="#boxplot-illustrating-sentiment-scores-entire-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boxplot Illustrating Sentiment Scores, Entire Dataset</h4>

<p><a href="http://imgur.com/X3n79rf"><img src="http://i.imgur.com/X3n79rf.png?1" title="source: imgur.com"></a></p>

<h2>
<a id="bank-a" class="anchor" href="#bank-a" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Bank A</em>
</h2>

<h3>
<a id="word-frequency-2" class="anchor" href="#word-frequency-2" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Word Frequency</strong>
</h3>

<p>Most frequently discussed words, related to banking, from the social media posts about Bank A:</p>

<ol>
<li>Time </li>
<li>Support</li>
<li>Share </li>
<li>Phone </li>
<li>People </li>
<li>Open </li>
<li>Mortgage </li>
<li>Money </li>
<li>Families </li>
<li>Donation </li>
<li>Deposit </li>
<li>Close </li>
<li>Check </li>
<li>Center </li>
</ol>

<h4>
<a id="frequency-plot-bank-a" class="anchor" href="#frequency-plot-bank-a" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency Plot, Bank A</h4>

<p><a href="http://imgur.com/zXoK8vL"><img src="http://i.imgur.com/zXoK8vL.png" title="source: imgur.com"></a></p>

<h5>
<a id="word-cloud-bank-a" class="anchor" href="#word-cloud-bank-a" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word Cloud, Bank A</h5>

<p><a href="http://imgur.com/mMAEZHI"><img src="http://i.imgur.com/mMAEZHI.png" title="source: imgur.com"></a></p>

<h3>
<a id="sentiment-analysis-3" class="anchor" href="#sentiment-analysis-3" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Sentiment Analysis</strong>
</h3>

<p>Average Sentiment Score of Entire Dataset: 65</p>

<p><em>Facebook was over twice as positive as Twitter, and Facebook had much more variability within and instances of strong sentiment.</em> </p>

<h4>
<a id="average-sentiment-scores-bank-a" class="anchor" href="#average-sentiment-scores-bank-a" aria-hidden="true"><span class="octicon octicon-link"></span></a>Average Sentiment Scores, Bank A</h4>

<p><a href="http://imgur.com/YPlwQKU"><img src="http://i.imgur.com/YPlwQKU.png" title="source: imgur.com"></a></p>

<h4>
<a id="boxplot-illustrating-sentiment-scores-bank-a" class="anchor" href="#boxplot-illustrating-sentiment-scores-bank-a" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boxplot Illustrating Sentiment Scores, Bank A</h4>

<p><a href="http://imgur.com/cmRPy4A"><img src="http://i.imgur.com/cmRPy4A.png" title="source: imgur.com"></a></p>

<h2>
<a id="bank-b" class="anchor" href="#bank-b" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Bank B</em>
</h2>

<h3>
<a id="word-frequency-3" class="anchor" href="#word-frequency-3" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Word Frequency</strong>
</h3>

<p>Most frequently discussed words, related to banking, from the social media posts about Bank B:</p>

<ol>
<li>Time </li>
<li>Team </li>
<li>Stadium </li>
<li>Service</li>
<li>People</li>
<li>Open </li>
<li>Mortgage</li>
<li>Money and Financial </li>
<li>Loan </li>
<li>Great/Good</li>
<li>Fee</li>
<li>Deposit</li>
<li>Charge </li>
<li>Cash </li>
<li>Business/Corporate </li>
<li>ATM </li>
<li>Account </li>
</ol>

<h4>
<a id="frequency-plot-bank-b" class="anchor" href="#frequency-plot-bank-b" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency Plot, Bank B</h4>

<p><a href="http://imgur.com/06WV2J9"><img src="http://i.imgur.com/06WV2J9.png" title="source: imgur.com"></a></p>

<h4>
<a id="word-cloud-bank-b" class="anchor" href="#word-cloud-bank-b" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word Cloud, Bank B</h4>

<p><a href="http://imgur.com/9sOdzGM"><img src="http://i.imgur.com/9sOdzGM.png" title="source: imgur.com"></a></p>

<h3>
<a id="sentiment-analysis-4" class="anchor" href="#sentiment-analysis-4" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Sentiment Analysis</strong>
</h3>

<p>Average Sentiment Score of Entire Dataset: 55</p>

<p><em>Facebook was slightly more positive as Twitter, and Facebook had slightly more variability within and instances of strong sentiment.</em> </p>

<h4>
<a id="average-sentiment-scores-bank-b" class="anchor" href="#average-sentiment-scores-bank-b" aria-hidden="true"><span class="octicon octicon-link"></span></a>Average Sentiment Scores, Bank B</h4>

<p><a href="http://imgur.com/Uf7DhrY"><img src="http://i.imgur.com/Uf7DhrY.png" title="source: imgur.com"></a></p>

<h4>
<a id="boxplot-illustrating-sentiment-scores-bank-b" class="anchor" href="#boxplot-illustrating-sentiment-scores-bank-b" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boxplot Illustrating Sentiment Scores, Bank B</h4>

<p><a href="http://imgur.com/wayNWPP"><img src="http://i.imgur.com/wayNWPP.png" title="source: imgur.com"></a></p>

<h3>
<a id="term-adjacency-matrix-bank-b" class="anchor" href="#term-adjacency-matrix-bank-b" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Term Adjacency Matrix, Bank B</strong>
</h3>

<p><a href="http://imgur.com/QX4YMdR"><img src="http://i.imgur.com/QX4YMdR.png" title="source: imgur.com"></a></p>

<h2>
<a id="bank-c" class="anchor" href="#bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Bank C</em>
</h2>

<h3>
<a id="word-frequency-4" class="anchor" href="#word-frequency-4" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Word Frequency</strong>
</h3>

<p>Most frequently discussed words, related to banking, from the social media posts about Bank C:</p>

<ol>
<li>Rate</li>
<li>Pay </li>
<li>Credit </li>
<li>Card </li>
<li>Buy</li>
<li>Business </li>
<li>Account </li>
</ol>

<h4>
<a id="frequency-plot-bank-c" class="anchor" href="#frequency-plot-bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency Plot, Bank C</h4>

<p><a href="http://imgur.com/x0EnllK"><img src="http://i.imgur.com/x0EnllK.png" title="source: imgur.com"></a></p>

<h4>
<a id="word-cloud-bank-c" class="anchor" href="#word-cloud-bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word Cloud, Bank C</h4>

<p><a href="http://imgur.com/B79ZjH6"><img src="http://i.imgur.com/B79ZjH6.png" title="source: imgur.com"></a></p>

<h3>
<a id="sentiment-analysis-5" class="anchor" href="#sentiment-analysis-5" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Sentiment Analysis</strong>
</h3>

<p>Average Sentiment Score of Entire Dataset: 52</p>

<p><em>Facebook was over three times more positive than Twitter, and Facebook had more variability within and instances of strong sentiment.</em></p>

<h4>
<a id="average-sentiment-scores-bank-c" class="anchor" href="#average-sentiment-scores-bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a>Average Sentiment Scores, Bank C</h4>

<p><a href="http://imgur.com/nSiQJDK"><img src="http://i.imgur.com/nSiQJDK.png" title="source: imgur.com"></a></p>

<h4>
<a id="boxplot-illustrating-sentiment-scores-bank-c" class="anchor" href="#boxplot-illustrating-sentiment-scores-bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boxplot Illustrating Sentiment Scores, Bank C</h4>

<p><a href="http://imgur.com/yZ5L1ei"><img src="http://i.imgur.com/yZ5L1ei.png" title="source: imgur.com"></a></p>

<h3>
<a id="term-adjacency-matrix-bank-c" class="anchor" href="#term-adjacency-matrix-bank-c" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Term Adjacency Matrix, Bank C</strong>
</h3>

<p><a href="http://imgur.com/ly19j7j"><img src="http://i.imgur.com/ly19j7j.png" title="source: imgur.com"></a></p>

<h2>
<a id="bank-d" class="anchor" href="#bank-d" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Bank D</em>
</h2>

<h3>
<a id="word-frequency-5" class="anchor" href="#word-frequency-5" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Word Frequency</strong>
</h3>

<p>Most frequently discussed words, related to banking, from the social media posts about Bank D:</p>

<ol>
<li>Small</li>
<li>Program </li>
<li>Mission </li>
<li>Manage </li>
<li>Learn </li>
<li>Application </li>
<li>Business</li>
</ol>

<h4>
<a id="frequency-plot-bank-d" class="anchor" href="#frequency-plot-bank-d" aria-hidden="true"><span class="octicon octicon-link"></span></a>Frequency Plot, Bank D</h4>

<p><a href="http://imgur.com/3MeTEd1"><img src="http://i.imgur.com/3MeTEd1.png" title="source: imgur.com"></a></p>

<h4>
<a id="word-cloud-bank-d" class="anchor" href="#word-cloud-bank-d" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word Cloud, Bank D</h4>

<p><a href="http://imgur.com/eNoAlVJ"><img src="http://i.imgur.com/eNoAlVJ.png" title="source: imgur.com"></a></p>

<h3>
<a id="sentiment-analysis-6" class="anchor" href="#sentiment-analysis-6" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Sentiment Analysis</strong>
</h3>

<p>Average Sentiment Score of Entire Dataset: 62</p>

<p><em>Facebook was slightly more positive as Twitter, and Facebook had slightly more variability within and instances of strong sentiment.</em></p>

<h4>
<a id="average-sentiment-scores-bank-d" class="anchor" href="#average-sentiment-scores-bank-d" aria-hidden="true"><span class="octicon octicon-link"></span></a>Average Sentiment Scores, Bank D</h4>

<p><a href="http://imgur.com/j74lcbn"><img src="http://i.imgur.com/j74lcbn.png" title="source: imgur.com"></a></p>

<h4>
<a id="boxplot-illustrating-sentiment-scores-bank-d" class="anchor" href="#boxplot-illustrating-sentiment-scores-bank-d" aria-hidden="true"><span class="octicon octicon-link"></span></a>Boxplot Illustrating Sentiment Scores, Bank D</h4>

<p><a href="http://imgur.com/VsC9Oly"><img src="http://i.imgur.com/VsC9Oly.png" title="source: imgur.com"></a></p>

<h3>
<a id="term-adjacency-matrix-bank-d" class="anchor" href="#term-adjacency-matrix-bank-d" aria-hidden="true"><span class="octicon octicon-link"></span></a><strong>Term Adjacency Matrix, Bank D</strong>
</h3>

<p><a href="http://imgur.com/oWMnz5B"><img src="http://i.imgur.com/oWMnz5B.png" title="source: imgur.com"></a></p>

<h3>
<a id="as-visually-evidenced-by-the-sentiment-bar-graphs-it-would-appear-that-positive-or-negative-sentiment-is-correlated-to-social-media-platform-in-each-of-the-individual-banks-as-well-as-the-entire-dataset-facebook-was-associated-with-more-positive-posts-while-twitter-was-conversely-associated-with-more-negative-posts-this-finding-implies-that-in-order-to-effectively-interpret-data-from-social-media-posts-data-should-be-collected-from-multiple-platforms-to-minimize-sampling-bias" class="anchor" href="#as-visually-evidenced-by-the-sentiment-bar-graphs-it-would-appear-that-positive-or-negative-sentiment-is-correlated-to-social-media-platform-in-each-of-the-individual-banks-as-well-as-the-entire-dataset-facebook-was-associated-with-more-positive-posts-while-twitter-was-conversely-associated-with-more-negative-posts-this-finding-implies-that-in-order-to-effectively-interpret-data-from-social-media-posts-data-should-be-collected-from-multiple-platforms-to-minimize-sampling-bias" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>As visually evidenced by the sentiment bar graphs, it would appear that positive or negative sentiment is correlated to social media platform. In each of the individual banks, as well as the entire dataset, Facebook was associated with more positive posts, while Twitter was conversely associated with more negative posts. This finding implies that, in order to effectively interpret data from social media posts, data should be collected from multiple platforms to minimize sampling bias.</em>
</h3>

<h3>
<a id="additionally-the-average-sentiment-score-between-all-of-the-banks-was-a-62-of-the-banks-of-interest-banks-a-d-only-bank-a-had-a-higher-mean-sentiment-score-than-62-banks-b-d-all-scored-below-60-with-scores-of-55-52-and-53-respectively-these-data-suggest-than-bank-a-is-associated-with-exceptionally-positive-social-media-posts-while-banks-b-d-are-associated-with-more-negative-sentiment-scores-below-average-overall-it-would-appear-that-there-are-differences--although-slight--that-may-be-seen-through-analyzing-the-positive-or-negative-connotations-of-social-media-posts-of-competing-businesses" class="anchor" href="#additionally-the-average-sentiment-score-between-all-of-the-banks-was-a-62-of-the-banks-of-interest-banks-a-d-only-bank-a-had-a-higher-mean-sentiment-score-than-62-banks-b-d-all-scored-below-60-with-scores-of-55-52-and-53-respectively-these-data-suggest-than-bank-a-is-associated-with-exceptionally-positive-social-media-posts-while-banks-b-d-are-associated-with-more-negative-sentiment-scores-below-average-overall-it-would-appear-that-there-are-differences--although-slight--that-may-be-seen-through-analyzing-the-positive-or-negative-connotations-of-social-media-posts-of-competing-businesses" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>Additionally, the average sentiment score between all of the banks was a 62. Of the banks of interest, Banks A-D, only Bank A had a higher mean sentiment score than 62. Banks B-D all scored below 60, with scores of 55, 52, and 53, respectively. These data suggest than Bank A is associated with exceptionally positive social media posts, while Banks B-D are associated with more negative sentiment scores below average. Overall, it would appear that there are differences- although slight- that may be seen through analyzing the positive or negative connotations of social media posts of competing businesses.</em>
</h3>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/emilyberich/Wells-Fargo-Analytics-Competition">Wells Fargo Analytics Competition</a> is maintained by <a href="https://github.com/emilyberich">emilyberich</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
